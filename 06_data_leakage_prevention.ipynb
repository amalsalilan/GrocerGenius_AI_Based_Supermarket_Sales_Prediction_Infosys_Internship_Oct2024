{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **IMPORTING LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **DATA PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Item_Fat_Content_Regular  Item_Type_Breads  Item_Type_Breakfast  \\\n",
      "7095                       1.0               0.0                  0.0   \n",
      "2936                       1.0               0.0                  0.0   \n",
      "2231                       0.0               0.0                  0.0   \n",
      "2135                       0.0               0.0                  0.0   \n",
      "724                        1.0               0.0                  0.0   \n",
      "\n",
      "      Item_Type_Canned  Item_Type_Dairy  Item_Type_Frozen Foods  \\\n",
      "7095               0.0              0.0                     1.0   \n",
      "2936               0.0              0.0                     0.0   \n",
      "2231               1.0              0.0                     0.0   \n",
      "2135               0.0              0.0                     0.0   \n",
      "724                0.0              0.0                     0.0   \n",
      "\n",
      "      Item_Type_Fruits and Vegetables  Item_Type_Hard Drinks  \\\n",
      "7095                              0.0                    0.0   \n",
      "2936                              1.0                    0.0   \n",
      "2231                              0.0                    0.0   \n",
      "2135                              0.0                    0.0   \n",
      "724                               0.0                    0.0   \n",
      "\n",
      "      Item_Type_Health and Hygiene  Item_Type_Household  ...  Item_MRP  \\\n",
      "7095                           0.0                  0.0  ...  0.421230   \n",
      "2936                           0.0                  0.0  ...  0.945457   \n",
      "2231                           0.0                  0.0  ...  0.639256   \n",
      "2135                           0.0                  0.0  ...  0.002547   \n",
      "724                            0.0                  0.0  ...  0.029690   \n",
      "\n",
      "      Item_Identifier  Outlet_Identifier  Outlet_Establishment_Year  \\\n",
      "7095      2271.853927        3697.731105                       1985   \n",
      "2936      2466.931353        2273.844916                       1999   \n",
      "2231      2690.182361        2264.102398                       1997   \n",
      "2135      1814.558430        2001.625449                       2009   \n",
      "724       1933.234628        2368.328533                       2007   \n",
      "\n",
      "      Item_Outlet_Sales  Outlet_age  Item_Weight_zscore  \\\n",
      "7095          5582.7330          39            0.009672   \n",
      "2936          1261.6910          25            0.009672   \n",
      "2231          4527.4400          27            0.189676   \n",
      "2135           366.1900          15            0.775993   \n",
      "724           1230.3984          17            0.635277   \n",
      "\n",
      "      Item_Visibility_zscore  Item_MRP_zscore  Item_Outlet_Sales_zscore  \n",
      "7095            1.472771e-16         0.159846                  2.006479  \n",
      "2936            1.696343e+00         1.819336                  0.536261  \n",
      "2231            7.567927e-01         0.663295                  1.385486  \n",
      "2135            5.893165e-01         1.740552                  1.063224  \n",
      "724             5.086393e-01         1.638076                  0.554676  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "      Item_Fat_Content_Regular  Item_Type_Breads  Item_Type_Breakfast  \\\n",
      "3467                       1.0               0.0                  0.0   \n",
      "5036                       0.0               0.0                  0.0   \n",
      "5618                       0.0               0.0                  0.0   \n",
      "7515                       1.0               0.0                  0.0   \n",
      "71                         1.0               0.0                  0.0   \n",
      "\n",
      "      Item_Type_Canned  Item_Type_Dairy  Item_Type_Frozen Foods  \\\n",
      "3467               0.0              0.0                     0.0   \n",
      "5036               0.0              0.0                     0.0   \n",
      "5618               0.0              0.0                     0.0   \n",
      "7515               0.0              0.0                     0.0   \n",
      "71                 0.0              0.0                     0.0   \n",
      "\n",
      "      Item_Type_Fruits and Vegetables  Item_Type_Hard Drinks  \\\n",
      "3467                              0.0                    0.0   \n",
      "5036                              0.0                    0.0   \n",
      "5618                              0.0                    0.0   \n",
      "7515                              0.0                    0.0   \n",
      "71                                0.0                    0.0   \n",
      "\n",
      "      Item_Type_Health and Hygiene  Item_Type_Household  ...  Item_MRP  \\\n",
      "3467                           0.0                  0.0  ...  0.076282   \n",
      "5036                           0.0                  0.0  ...  0.552801   \n",
      "5618                           0.0                  0.0  ...  0.308511   \n",
      "7515                           0.0                  0.0  ...  0.143350   \n",
      "71                             0.0                  0.0  ...  0.115554   \n",
      "\n",
      "      Item_Identifier  Outlet_Identifier  Outlet_Establishment_Year  \\\n",
      "3467      1967.000647        2258.897218                       2007   \n",
      "5036      2275.783188        2451.199606                       2004   \n",
      "5618      2073.820216        2258.897218                       2007   \n",
      "7515      1925.615279        2312.747602                       1987   \n",
      "71        1997.090565        2312.747602                       1987   \n",
      "\n",
      "      Item_Outlet_Sales  Outlet_age  Item_Weight_zscore  \\\n",
      "3467           506.0080          17            0.730596   \n",
      "5036          4094.6700          20            1.137541   \n",
      "5618          1065.2800          17            0.838160   \n",
      "7515           391.4904          37            0.035819   \n",
      "71             599.2200          37            0.718407   \n",
      "\n",
      "      Item_Visibility_zscore  Item_MRP_zscore  Item_Outlet_Sales_zscore  \n",
      "3467                1.415928         1.494038                  0.983953  \n",
      "5036                0.686793         0.314049                  1.092954  \n",
      "5618                1.137023         0.612874                  0.660279  \n",
      "7515                0.003813         1.239555                  1.050229  \n",
      "71                  1.019415         1.345023                  0.930007  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "# Defining a function to preprocess the data\n",
    "\n",
    "def data_process(data):\n",
    "    \n",
    "    # Step 1: Handling Missing values\n",
    "    # Finding the mean of 'Item_Visibility' where it is greater than 0, as a placeholder for missing values\n",
    "    non_zero_mean = data.loc[data['Item_Visibility'] > 0, 'Item_Visibility'].mean()\n",
    "    data['Item_Visibility'] = data['Item_Visibility'].replace(0, non_zero_mean)\n",
    "\n",
    "    # Filling missing 'Item_Weight' based on median of 'Item_Type'.\n",
    "    data['Item_Weight'] = data['Item_Weight'].fillna(data.groupby('Item_Type')['Item_Weight'].transform('median'))\n",
    "\n",
    "    # Filling missing 'Outlet_Size' with the mode of each 'Outlet_Type' group.\n",
    "    data['Outlet_Size'] = data['Outlet_Size'].fillna(\n",
    "        data.groupby('Outlet_Type')['Outlet_Size'].transform(lambda x: x.mode()[0] if not x.mode().empty else 'Unknown')\n",
    "    )\n",
    "\n",
    "    # The column has inconsistent labels for 'Low Fat' and 'Regular', so standardizing these values.\n",
    "    data.replace({'Item_Fat_Content': {'low fat': 'Low Fat', 'LF': 'Low Fat', 'reg': 'Regular'}}, inplace=True)\n",
    "\n",
    "    # Step 2: Feature Derivation\n",
    "    # Creating a new column 'Outlet_age' to calculate the store's age based on its establishment year\n",
    "    data['Outlet_age'] = 2024 - data['Outlet_Establishment_Year']\n",
    "\n",
    "    # Step 3: Encoding\n",
    "    # Target Encoding for high-cardinality categorical features, assigns a mean 'Item_Outlet_Sales' value to each category.\n",
    "    high_cardinality_columns = ['Item_Identifier', 'Outlet_Identifier']\n",
    "    target_encoder = TargetEncoder(cols=high_cardinality_columns)\n",
    "    data = target_encoder.fit_transform(data, data['Item_Outlet_Sales'])\n",
    "\n",
    "    # Identifying categorical and numerical columns for encoding and scaling\n",
    "    nominal_columns = ['Item_Fat_Content', 'Item_Type', 'Outlet_Location_Type', 'Outlet_Type']\n",
    "    ordinal_columns = ['Outlet_Size']\n",
    "    numerical_columns = ['Item_Weight', 'Item_Visibility', 'Item_MRP']\n",
    "\n",
    "    # Mapping for ordinal encoding for 'Outlet_Size'\n",
    "    Outlet_Size_mapping = ['Small', 'Medium', 'High']\n",
    "    ohe = OneHotEncoder(drop='first', sparse_output=False)  # One-Hot Encoder for nominal columns\n",
    "    ode = OrdinalEncoder(categories=[Outlet_Size_mapping])  # Ordinal Encoder for 'Outlet_Size'\n",
    "    scaler = StandardScaler()  # Standard Scaler for numerical columns\n",
    "\n",
    "    # Step 4: Column Transformer setup\n",
    "    ct = make_column_transformer(\n",
    "        (ohe, nominal_columns),\n",
    "        (ode, ordinal_columns),\n",
    "        (scaler, numerical_columns),\n",
    "        remainder='passthrough'  # Remaining columns are kept as-is\n",
    "    )\n",
    "    ct.set_output(transform='pandas')\n",
    "    df_encoded = ct.fit_transform(data)\n",
    "\n",
    "    # We clean up encoded column names for easier interpretation and further analysis.\n",
    "    df_encoded.columns = [\n",
    "        col.replace(\"onehotencoder__\", \"\")\n",
    "           .replace(\"ordinalencoder__\", \"\")\n",
    "           .replace(\"standardscaler__\", \"\")\n",
    "           .replace(\"remainder__\", \"\")\n",
    "        for col in df_encoded.columns\n",
    "    ]\n",
    "\n",
    "    # Step 5: Outlier Detection and Handling\n",
    "    # Z-score to indentify outliers and using cap method to handle them instead of removing\n",
    "    continuous_columns = ['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Item_Outlet_Sales']\n",
    "    z_threshold = 2.5  # as 3 results with 0 outliers & 2 with many so fixed T as 2.5\n",
    "\n",
    "    for col in continuous_columns:\n",
    "        df_encoded[col + '_zscore'] = np.abs((df_encoded[col] - df_encoded[col].mean()) / df_encoded[col].std())\n",
    "        upper_bound = df_encoded[col].mean() + z_threshold * df_encoded[col].std()\n",
    "        lower_bound = df_encoded[col].mean() - z_threshold * df_encoded[col].std()\n",
    "        df_encoded[col] = np.where(df_encoded[col] > upper_bound, upper_bound,\n",
    "                                   np.where(df_encoded[col] < lower_bound, lower_bound, df_encoded[col]))\n",
    "\n",
    "    # Step 6: Feature Scaling using Min-Max Normalization \n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    df_encoded[['Item_MRP', 'Item_Visibility']] = min_max_scaler.fit_transform(df_encoded[['Item_MRP', 'Item_Visibility']])\n",
    "\n",
    "    # Save encoders and scalers\n",
    "    with open('target_encoder.pkl', 'wb') as file:\n",
    "        pickle.dump(target_encoder, file)\n",
    "    with open('onehot_encoder.pkl', 'wb') as file:\n",
    "        pickle.dump(ohe, file)\n",
    "    with open('ordinal_encoder.pkl', 'wb') as file:\n",
    "        pickle.dump(ode, file)\n",
    "    with open('scaler.pkl', 'wb') as file:\n",
    "        pickle.dump(scaler, file)\n",
    "    with open('minmax_scaler.pkl', 'wb') as file:\n",
    "        pickle.dump(min_max_scaler, file)\n",
    "\n",
    "    #print(\"Encoders and scalers have been saved successfully.\")\n",
    "    \n",
    "    # Return the processed DataFrame\n",
    "    return df_encoded\n",
    "    \n",
    "\n",
    "# Loading the raw data\n",
    "data = pd.read_csv('C:\\\\Users\\\\Kamlesh P Panchal\\\\Documents\\\\Infosys Internship\\\\train_og\\\\Train.csv')\n",
    "\n",
    "# Splittig into training and testing sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "training, testing = train_test_split(data)\n",
    "\n",
    "# Passing the training and testing data\n",
    "training_data_processed = data_process(training)\n",
    "testing_data_processed = data_process(testing)\n",
    "\n",
    "print(training_data_processed.head())\n",
    "print(testing_data_processed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Training Data: (6392, 34)\n",
      "Shape of the Testing Data: (2131, 34)\n"
     ]
    }
   ],
   "source": [
    "# Shape of the Training & Testing Data\n",
    "print(\"Shape of the Training Data:\",training_data_processed.shape)\n",
    "print(\"Shape of the Testing Data:\",testing_data_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: Item_Fat_Content_Regular           0\n",
      "Item_Type_Breads                   0\n",
      "Item_Type_Breakfast                0\n",
      "Item_Type_Canned                   0\n",
      "Item_Type_Dairy                    0\n",
      "Item_Type_Frozen Foods             0\n",
      "Item_Type_Fruits and Vegetables    0\n",
      "Item_Type_Hard Drinks              0\n",
      "Item_Type_Health and Hygiene       0\n",
      "Item_Type_Household                0\n",
      "Item_Type_Meat                     0\n",
      "Item_Type_Others                   0\n",
      "Item_Type_Seafood                  0\n",
      "Item_Type_Snack Foods              0\n",
      "Item_Type_Soft Drinks              0\n",
      "Item_Type_Starchy Foods            0\n",
      "Outlet_Location_Type_Tier 2        0\n",
      "Outlet_Location_Type_Tier 3        0\n",
      "Outlet_Type_Supermarket Type1      0\n",
      "Outlet_Type_Supermarket Type2      0\n",
      "Outlet_Type_Supermarket Type3      0\n",
      "Outlet_Size                        0\n",
      "Item_Weight                        0\n",
      "Item_Visibility                    0\n",
      "Item_MRP                           0\n",
      "Item_Identifier                    0\n",
      "Outlet_Identifier                  0\n",
      "Outlet_Establishment_Year          0\n",
      "Item_Outlet_Sales                  0\n",
      "Outlet_age                         0\n",
      "Item_Weight_zscore                 0\n",
      "Item_Visibility_zscore             0\n",
      "Item_MRP_zscore                    0\n",
      "Item_Outlet_Sales_zscore           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking again for missing values\n",
    "print(\"Train Data:\", training_data_processed.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data: Item_Fat_Content_Regular           0\n",
      "Item_Type_Breads                   0\n",
      "Item_Type_Breakfast                0\n",
      "Item_Type_Canned                   0\n",
      "Item_Type_Dairy                    0\n",
      "Item_Type_Frozen Foods             0\n",
      "Item_Type_Fruits and Vegetables    0\n",
      "Item_Type_Hard Drinks              0\n",
      "Item_Type_Health and Hygiene       0\n",
      "Item_Type_Household                0\n",
      "Item_Type_Meat                     0\n",
      "Item_Type_Others                   0\n",
      "Item_Type_Seafood                  0\n",
      "Item_Type_Snack Foods              0\n",
      "Item_Type_Soft Drinks              0\n",
      "Item_Type_Starchy Foods            0\n",
      "Outlet_Location_Type_Tier 2        0\n",
      "Outlet_Location_Type_Tier 3        0\n",
      "Outlet_Type_Supermarket Type1      0\n",
      "Outlet_Type_Supermarket Type2      0\n",
      "Outlet_Type_Supermarket Type3      0\n",
      "Outlet_Size                        0\n",
      "Item_Weight                        0\n",
      "Item_Visibility                    0\n",
      "Item_MRP                           0\n",
      "Item_Identifier                    0\n",
      "Outlet_Identifier                  0\n",
      "Outlet_Establishment_Year          0\n",
      "Item_Outlet_Sales                  0\n",
      "Outlet_age                         0\n",
      "Item_Weight_zscore                 0\n",
      "Item_Visibility_zscore             0\n",
      "Item_MRP_zscore                    0\n",
      "Item_Outlet_Sales_zscore           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Data:\",testing_data_processed.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **TRAINING & TESTING THE DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model  Training R²  Testing R²\n",
      "0             Linear Regression     0.766201    0.786412\n",
      "1                 Random Forest     0.985079    0.915124\n",
      "2     Support Vector Regression     0.052654    0.050052\n",
      "3                KNN Regression     0.763015    0.673817\n",
      "4            XGBoost Regression     0.983446    0.859878\n",
      "5              Lasso Regression     0.765896    0.786240\n",
      "6              Ridge Regression     0.766170    0.786079\n",
      "7           AdaBoost Regression     0.824312    0.811841\n",
      "8  Gradient Boosting Regression     0.901413    0.912770\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Separating features and target variable\n",
    "X_train = training_data_processed.drop('Item_Outlet_Sales', axis=1)\n",
    "y_train = training_data_processed['Item_Outlet_Sales']\n",
    "\n",
    "X_test = testing_data_processed.drop('Item_Outlet_Sales', axis=1)\n",
    "y_test = testing_data_processed['Item_Outlet_Sales']\n",
    "\n",
    "# Initializing models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Support Vector Regression': SVR(),\n",
    "    'KNN Regression': KNeighborsRegressor(),\n",
    "    'XGBoost Regression': XGBRegressor(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'AdaBoost Regression': AdaBoostRegressor(),\n",
    "    'Gradient Boosting Regression': GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "# Dictionary to store R² scores\n",
    "r2_scores = {'Model': [], 'Training R²': [], 'Testing R²': []}\n",
    "\n",
    "# Training the models and calculating R² scores\n",
    "for model_name, model in models.items():\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting on training and testing data\n",
    "    train_preds = model.predict(X_train)\n",
    "    test_preds = model.predict(X_test)\n",
    "\n",
    "    # Calculating R² scores\n",
    "    train_r2 = r2_score(y_train, train_preds)\n",
    "    test_r2 = r2_score(y_test, test_preds)\n",
    "\n",
    "    # Storing results\n",
    "    r2_scores['Model'].append(model_name)\n",
    "    r2_scores['Training R²'].append(train_r2)\n",
    "    r2_scores['Testing R²'].append(test_r2)\n",
    "\n",
    "# Converting results to a DataFrame \n",
    "r2_scores_df = pd.DataFrame(r2_scores)\n",
    "\n",
    "print(r2_scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best Parameters for Random Forest: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None, 'max_depth': 10}\n",
      "R² on Training Data (Random Forest): 0.9377\n",
      "R² on Testing Data (Random Forest): 0.9202\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------------------\n",
    "# Random Forest Regressor\n",
    "# ----------------------------------\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define parameter grid for Random Forest\n",
    "param_dist_rf = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None]  # Valid options for max_features\n",
    "}\n",
    "\n",
    "# Initialize Random Forest model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Perform RandomizedSearchCV for Random Forest\n",
    "random_search_rf = RandomizedSearchCV(rf, param_distributions=param_dist_rf, n_iter=10, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "random_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Best Random Forest model\n",
    "best_rf = random_search_rf.best_estimator_\n",
    "\n",
    "# Predictions for Random Forest\n",
    "y_train_pred_rf = best_rf.predict(X_train)\n",
    "y_test_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "# Calculate R² scores for Random Forest\n",
    "train_r2_rf = r2_score(y_train, y_train_pred_rf)\n",
    "test_r2_rf = r2_score(y_test, y_test_pred_rf)\n",
    "\n",
    "# Print Random Forest results\n",
    "print(\"Best Parameters for Random Forest:\", random_search_rf.best_params_)\n",
    "print(f\"R² on Training Data (Random Forest): {train_r2_rf:.4f}\")\n",
    "print(f\"R² on Testing Data (Random Forest): {test_r2_rf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best Parameters for XGBoost: {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1, 'gamma': 0.1, 'colsample_bytree': 0.9}\n",
      "R² on Training Data (XGBoost): 0.9280\n",
      "R² on Testing Data (XGBoost): 0.8745\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------\n",
    "# XGBoost Regressor\n",
    "# ----------------------------------\n",
    "\n",
    "# Define parameter grid for XGBoost\n",
    "param_dist_xgb = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Initialize XGBoost model\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "# Perform RandomizedSearchCV for XGBoost\n",
    "random_search_xgb = RandomizedSearchCV(xgb, param_distributions=param_dist_xgb, n_iter=10, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "random_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Best XGBoost model\n",
    "best_xgb = random_search_xgb.best_estimator_\n",
    "\n",
    "# Predictions for XGBoost\n",
    "y_train_pred_xgb = best_xgb.predict(X_train)\n",
    "y_test_pred_xgb = best_xgb.predict(X_test)\n",
    "\n",
    "# Calculate R² scores for XGBoost\n",
    "train_r2_xgb = r2_score(y_train, y_train_pred_xgb)\n",
    "test_r2_xgb = r2_score(y_test, y_test_pred_xgb)\n",
    "\n",
    "# Print XGBoost results\n",
    "print(\"Best Parameters for XGBoost:\", random_search_xgb.best_params_)\n",
    "print(f\"R² on Training Data (XGBoost): {train_r2_xgb:.4f}\")\n",
    "print(f\"R² on Testing Data (XGBoost): {test_r2_xgb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best Parameters for Gradient Boosting: {'subsample': 1.0, 'n_estimators': 50, 'max_depth': 7, 'learning_rate': 0.1}\n",
      "R² on Training Data (Gradient Boosting): 0.9442\n",
      "R² on Testing Data (Gradient Boosting): 0.9178\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------------------------\n",
    "# Gradient Boosting Regressor\n",
    "# ----------------------------------\n",
    "\n",
    "# Define parameter grid for Gradient Boosting\n",
    "param_dist_gb = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize Gradient Boosting model\n",
    "gb = GradientBoostingRegressor()\n",
    "\n",
    "# Perform RandomizedSearchCV for Gradient Boosting\n",
    "random_search_gb = RandomizedSearchCV(gb, param_distributions=param_dist_gb, n_iter=10, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "random_search_gb.fit(X_train, y_train)\n",
    "\n",
    "# Best Gradient Boosting model\n",
    "best_gb = random_search_gb.best_estimator_\n",
    "\n",
    "# Predictions for Gradient Boosting\n",
    "y_train_pred_gb = best_gb.predict(X_train)\n",
    "y_test_pred_gb = best_gb.predict(X_test)\n",
    "\n",
    "# Calculate R² scores for Gradient Boosting\n",
    "train_r2_gb = r2_score(y_train, y_train_pred_gb)\n",
    "test_r2_gb = r2_score(y_test, y_test_pred_gb)\n",
    "\n",
    "# Print Gradient Boosting results\n",
    "print(\"Best Parameters for Gradient Boosting:\", random_search_gb.best_params_)\n",
    "print(f\"R² on Training Data (Gradient Boosting): {train_r2_gb:.4f}\")\n",
    "print(f\"R² on Testing Data (Gradient Boosting): {test_r2_gb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'best_xgb_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the best XGBoost model\n",
    "joblib.dump(best_xgb, 'best_xgb_model.pkl')\n",
    "\n",
    "print(\"Model saved as 'best_xgb_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
