{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0263b5aa-2060-47c3-a198-2105dd75dc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in c:\\users\\rauni\\anaconda3\\lib\\site-packages (2.6.4)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\rauni\\anaconda3\\lib\\site-packages (from category_encoders) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\rauni\\anaconda3\\lib\\site-packages (from category_encoders) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\rauni\\anaconda3\\lib\\site-packages (from category_encoders) (1.13.1)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\rauni\\anaconda3\\lib\\site-packages (from category_encoders) (0.14.2)\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\users\\rauni\\anaconda3\\lib\\site-packages (from category_encoders) (2.2.2)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\rauni\\anaconda3\\lib\\site-packages (from category_encoders) (0.5.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rauni\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rauni\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rauni\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2023.3)\n",
      "Requirement already satisfied: six in c:\\users\\rauni\\anaconda3\\lib\\site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\rauni\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rauni\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (2.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\rauni\\anaconda3\\lib\\site-packages (from statsmodels>=0.9.0->category_encoders) (23.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install category_encoders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fa12030-caa7-4afd-8939-fec2c65eb41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a3f4839-261c-4f76-a32b-d378b2b34189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Item_Fat_Content_Regular  Item_Type_Breads  Item_Type_Breakfast  \\\n",
      "429                        0.0               0.0                  0.0   \n",
      "4710                       0.0               0.0                  0.0   \n",
      "6052                       0.0               0.0                  0.0   \n",
      "1370                       1.0               0.0                  0.0   \n",
      "1943                       0.0               1.0                  0.0   \n",
      "\n",
      "      Item_Type_Canned  Item_Type_Dairy  Item_Type_Frozen Foods  \\\n",
      "429                0.0              1.0                     0.0   \n",
      "4710               0.0              0.0                     0.0   \n",
      "6052               0.0              0.0                     0.0   \n",
      "1370               0.0              1.0                     0.0   \n",
      "1943               0.0              0.0                     0.0   \n",
      "\n",
      "      Item_Type_Fruits and Vegetables  Item_Type_Hard Drinks  \\\n",
      "429                               0.0                    0.0   \n",
      "4710                              1.0                    0.0   \n",
      "6052                              0.0                    0.0   \n",
      "1370                              0.0                    0.0   \n",
      "1943                              0.0                    0.0   \n",
      "\n",
      "      Item_Type_Health and Hygiene  Item_Type_Household  ...  Item_MRP  \\\n",
      "429                            0.0                  0.0  ...  0.085154   \n",
      "4710                           0.0                  0.0  ...  0.785590   \n",
      "6052                           0.0                  1.0  ...  0.382549   \n",
      "1370                           0.0                  0.0  ...  0.639094   \n",
      "1943                           0.0                  0.0  ...  0.406160   \n",
      "\n",
      "      Item_Identifier  Outlet_Identifier  Outlet_Establishment_Year  \\\n",
      "429       1863.646027        2152.237497                       2002   \n",
      "4710      2401.876541        2152.237497                       2002   \n",
      "6052      2291.861574        2414.289719                       1999   \n",
      "1370      2210.678436        2312.833457                       2007   \n",
      "1943      2115.574965        2152.237497                       2002   \n",
      "\n",
      "      Item_Outlet_Sales  Outlet_age  Item_Weight_zscore  \\\n",
      "429            848.8950          22            1.144705   \n",
      "4710          2830.3158          22            0.541421   \n",
      "6052          4020.7662          25            1.365070   \n",
      "1370          5954.2494          17            0.776749   \n",
      "1943          2826.9868          22            1.921288   \n",
      "\n",
      "      Item_Visibility_zscore  Item_MRP_zscore  Item_Outlet_Sales_zscore  \n",
      "429             1.104603e+00         1.439743                  0.774438  \n",
      "4710            6.002238e-17         1.206770                  0.384870  \n",
      "6052            1.197550e+00         0.316071                  1.081390  \n",
      "1370            1.479700e-01         0.653255                  2.212651  \n",
      "1943            1.446166e+00         0.226860                  0.382923  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "      Item_Fat_Content_Regular  Item_Type_Breads  Item_Type_Breakfast  \\\n",
      "3054                       1.0               0.0                  0.0   \n",
      "805                        0.0               0.0                  0.0   \n",
      "6046                       0.0               0.0                  0.0   \n",
      "3901                       1.0               0.0                  0.0   \n",
      "3982                       0.0               0.0                  0.0   \n",
      "\n",
      "      Item_Type_Canned  Item_Type_Dairy  Item_Type_Frozen Foods  \\\n",
      "3054               0.0              0.0                     1.0   \n",
      "805                0.0              0.0                     0.0   \n",
      "6046               0.0              0.0                     0.0   \n",
      "3901               0.0              0.0                     0.0   \n",
      "3982               0.0              1.0                     0.0   \n",
      "\n",
      "      Item_Type_Fruits and Vegetables  Item_Type_Hard Drinks  \\\n",
      "3054                              0.0                    0.0   \n",
      "805                               0.0                    0.0   \n",
      "6046                              1.0                    0.0   \n",
      "3901                              0.0                    0.0   \n",
      "3982                              0.0                    0.0   \n",
      "\n",
      "      Item_Type_Health and Hygiene  Item_Type_Household  ...  Item_MRP  \\\n",
      "3054                           0.0                  0.0  ...  0.466451   \n",
      "805                            0.0                  0.0  ...  0.348756   \n",
      "6046                           0.0                  0.0  ...  0.114611   \n",
      "3901                           0.0                  0.0  ...  0.089364   \n",
      "3982                           0.0                  0.0  ...  0.692108   \n",
      "\n",
      "      Item_Identifier  Outlet_Identifier  Outlet_Establishment_Year  \\\n",
      "3054      1938.907306         363.140020                       1998   \n",
      "805       2102.726801        3645.942993                       1985   \n",
      "6046      2012.632486        2147.682639                       1999   \n",
      "3901      1990.662241        2017.603586                       2009   \n",
      "3982      2519.129742        2337.090583                       1997   \n",
      "\n",
      "      Item_Outlet_Sales  Outlet_age  Item_Weight_zscore  \\\n",
      "3054           142.4812          26            0.269268   \n",
      "805           3355.6320          39            0.103424   \n",
      "6046           848.8950          25            1.618056   \n",
      "3901           615.1992          15            0.423077   \n",
      "3982          4602.0096          27            0.487947   \n",
      "\n",
      "      Item_Visibility_zscore  Item_MRP_zscore  Item_Outlet_Sales_zscore  \n",
      "3054                2.173436         0.008186                  1.215716  \n",
      "805                 0.232621         0.435940                  0.675839  \n",
      "6046                0.325618         1.319494                  0.799856  \n",
      "3901                0.616072         1.414766                  0.937431  \n",
      "3982                0.270074         0.859714                  1.409571  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Defining a function to preprocess the data\n",
    "\n",
    "def data_process(data):\n",
    "    \n",
    "    # Step 1: Handling Missing values\n",
    "    # Finding the mean of 'Item_Visibility' where it is greater than 0, as a placeholder for missing values\n",
    "    non_zero_mean = data.loc[data['Item_Visibility'] > 0, 'Item_Visibility'].mean()\n",
    "    data['Item_Visibility'] = data['Item_Visibility'].replace(0, non_zero_mean)\n",
    "\n",
    "    # Filling missing 'Item_Weight' based on median of 'Item_Type'.\n",
    "    data['Item_Weight'] = data['Item_Weight'].fillna(data.groupby('Item_Type')['Item_Weight'].transform('median'))\n",
    "\n",
    "    # Filling missing 'Outlet_Size' with the mode of each 'Outlet_Type' group.\n",
    "    data['Outlet_Size'] = data['Outlet_Size'].fillna(\n",
    "        data.groupby('Outlet_Type')['Outlet_Size'].transform(lambda x: x.mode()[0] if not x.mode().empty else 'Unknown')\n",
    "    )\n",
    "\n",
    "    # The column has inconsistent labels for 'Low Fat' and 'Regular', so standardizing these values.\n",
    "    data.replace({'Item_Fat_Content': {'low fat': 'Low Fat', 'LF': 'Low Fat', 'reg': 'Regular'}}, inplace=True)\n",
    "\n",
    "    # Step 2: Feature Derivation\n",
    "    # Creating a new column 'Outlet_age' to calculate the store's age based on its establishment year\n",
    "    data['Outlet_age'] = 2024 - data['Outlet_Establishment_Year']\n",
    "\n",
    "    # Step 3: Encoding\n",
    "    # Target Encoding for high-cardinality categorical features, assigns a mean 'Item_Outlet_Sales' value to each category.\n",
    "    high_cardinality_columns = ['Item_Identifier', 'Outlet_Identifier']\n",
    "    target_encoder = TargetEncoder(cols=high_cardinality_columns)\n",
    "    data = target_encoder.fit_transform(data, data['Item_Outlet_Sales'])\n",
    "\n",
    "    # Identifying categorical and numerical columns for encoding and scaling\n",
    "    nominal_columns = ['Item_Fat_Content', 'Item_Type', 'Outlet_Location_Type', 'Outlet_Type']\n",
    "    ordinal_columns = ['Outlet_Size']\n",
    "    numerical_columns = ['Item_Weight', 'Item_Visibility', 'Item_MRP']\n",
    "\n",
    "    # Mapping for ordinal encoding for 'Outlet_Size'\n",
    "    Outlet_Size_mapping = ['Small', 'Medium', 'High']\n",
    "    ohe = OneHotEncoder(drop='first', sparse_output=False)  # One-Hot Encoder for nominal columns\n",
    "    ode = OrdinalEncoder(categories=[Outlet_Size_mapping])  # Ordinal Encoder for 'Outlet_Size'\n",
    "    scaler = StandardScaler()  # Standard Scaler for numerical columns\n",
    "\n",
    "    # Step 4: Column Transformer setup\n",
    "    ct = make_column_transformer(\n",
    "        (ohe, nominal_columns),\n",
    "        (ode, ordinal_columns),\n",
    "        (scaler, numerical_columns),\n",
    "        remainder='passthrough'  # Remaining columns are kept as-is\n",
    "    )\n",
    "    ct.set_output(transform='pandas')\n",
    "    df_encoded = ct.fit_transform(data)\n",
    "\n",
    "    # We clean up encoded column names for easier interpretation and further analysis.\n",
    "    df_encoded.columns = [\n",
    "        col.replace(\"onehotencoder__\", \"\")\n",
    "           .replace(\"ordinalencoder__\", \"\")\n",
    "           .replace(\"standardscaler__\", \"\")\n",
    "           .replace(\"remainder__\", \"\")\n",
    "        for col in df_encoded.columns\n",
    "    ]\n",
    "\n",
    "    # Step 5: Outlier Detection and Handling\n",
    "    # Z-score to indentify outliers and using cap method to handle them instead of removing\n",
    "    continuous_columns = ['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Item_Outlet_Sales']\n",
    "    z_threshold = 2.5  # as 3 results with 0 outliers & 2 with many so fixed T as 2.5\n",
    "\n",
    "    for col in continuous_columns:\n",
    "        df_encoded[col + '_zscore'] = np.abs((df_encoded[col] - df_encoded[col].mean()) / df_encoded[col].std())\n",
    "        upper_bound = df_encoded[col].mean() + z_threshold * df_encoded[col].std()\n",
    "        lower_bound = df_encoded[col].mean() - z_threshold * df_encoded[col].std()\n",
    "        df_encoded[col] = np.where(df_encoded[col] > upper_bound, upper_bound,\n",
    "                                   np.where(df_encoded[col] < lower_bound, lower_bound, df_encoded[col]))\n",
    "\n",
    "    # Step 6: Feature Scaling using Min-Max Normalization \n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    df_encoded[['Item_MRP', 'Item_Visibility']] = min_max_scaler.fit_transform(df_encoded[['Item_MRP', 'Item_Visibility']])\n",
    "\n",
    "    # Save encoders and scalers\n",
    "    with open('target_encoder.pkl', 'wb') as file:\n",
    "        pickle.dump(target_encoder, file)\n",
    "    with open('onehot_encoder.pkl', 'wb') as file:\n",
    "        pickle.dump(ohe, file)\n",
    "    with open('ordinal_encoder.pkl', 'wb') as file:\n",
    "        pickle.dump(ode, file)\n",
    "    with open('scaler.pkl', 'wb') as file:\n",
    "        pickle.dump(scaler, file)\n",
    "    with open('minmax_scaler.pkl', 'wb') as file:\n",
    "        pickle.dump(min_max_scaler, file)\n",
    "\n",
    "    #print(\"Encoders and scalers have been saved successfully.\")\n",
    "    \n",
    "    # Return the processed DataFrame\n",
    "    return df_encoded\n",
    "    \n",
    "\n",
    "# Loading the raw data\n",
    "data = pd.read_csv('Train.csv')\n",
    "\n",
    "# Splittig into training and testing sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "training, testing = train_test_split(data)\n",
    "\n",
    "# Passing the training and testing data\n",
    "training_data_processed = data_process(training)\n",
    "testing_data_processed = data_process(testing)\n",
    "\n",
    "print(training_data_processed.head())\n",
    "print(testing_data_processed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0183aa1d-41ba-4acc-bda0-955b9aaab3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Training Data: (6392, 34)\n",
      "Shape of the Testing Data: (2131, 34)\n"
     ]
    }
   ],
   "source": [
    "# Shape of the Training & Testing Data\n",
    "print(\"Shape of the Training Data:\",training_data_processed.shape)\n",
    "print(\"Shape of the Testing Data:\",testing_data_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96b1848d-487d-4ff5-af19-d1f7637ab1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: Item_Fat_Content_Regular           0\n",
      "Item_Type_Breads                   0\n",
      "Item_Type_Breakfast                0\n",
      "Item_Type_Canned                   0\n",
      "Item_Type_Dairy                    0\n",
      "Item_Type_Frozen Foods             0\n",
      "Item_Type_Fruits and Vegetables    0\n",
      "Item_Type_Hard Drinks              0\n",
      "Item_Type_Health and Hygiene       0\n",
      "Item_Type_Household                0\n",
      "Item_Type_Meat                     0\n",
      "Item_Type_Others                   0\n",
      "Item_Type_Seafood                  0\n",
      "Item_Type_Snack Foods              0\n",
      "Item_Type_Soft Drinks              0\n",
      "Item_Type_Starchy Foods            0\n",
      "Outlet_Location_Type_Tier 2        0\n",
      "Outlet_Location_Type_Tier 3        0\n",
      "Outlet_Type_Supermarket Type1      0\n",
      "Outlet_Type_Supermarket Type2      0\n",
      "Outlet_Type_Supermarket Type3      0\n",
      "Outlet_Size                        0\n",
      "Item_Weight                        0\n",
      "Item_Visibility                    0\n",
      "Item_MRP                           0\n",
      "Item_Identifier                    0\n",
      "Outlet_Identifier                  0\n",
      "Outlet_Establishment_Year          0\n",
      "Item_Outlet_Sales                  0\n",
      "Outlet_age                         0\n",
      "Item_Weight_zscore                 0\n",
      "Item_Visibility_zscore             0\n",
      "Item_MRP_zscore                    0\n",
      "Item_Outlet_Sales_zscore           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Data:\", training_data_processed.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd12f007-ada1-48f0-afd7-5e7c48b63fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data: Item_Fat_Content_Regular           0\n",
      "Item_Type_Breads                   0\n",
      "Item_Type_Breakfast                0\n",
      "Item_Type_Canned                   0\n",
      "Item_Type_Dairy                    0\n",
      "Item_Type_Frozen Foods             0\n",
      "Item_Type_Fruits and Vegetables    0\n",
      "Item_Type_Hard Drinks              0\n",
      "Item_Type_Health and Hygiene       0\n",
      "Item_Type_Household                0\n",
      "Item_Type_Meat                     0\n",
      "Item_Type_Others                   0\n",
      "Item_Type_Seafood                  0\n",
      "Item_Type_Snack Foods              0\n",
      "Item_Type_Soft Drinks              0\n",
      "Item_Type_Starchy Foods            0\n",
      "Outlet_Location_Type_Tier 2        0\n",
      "Outlet_Location_Type_Tier 3        0\n",
      "Outlet_Type_Supermarket Type1      0\n",
      "Outlet_Type_Supermarket Type2      0\n",
      "Outlet_Type_Supermarket Type3      0\n",
      "Outlet_Size                        0\n",
      "Item_Weight                        0\n",
      "Item_Visibility                    0\n",
      "Item_MRP                           0\n",
      "Item_Identifier                    0\n",
      "Outlet_Identifier                  0\n",
      "Outlet_Establishment_Year          0\n",
      "Item_Outlet_Sales                  0\n",
      "Outlet_age                         0\n",
      "Item_Weight_zscore                 0\n",
      "Item_Visibility_zscore             0\n",
      "Item_MRP_zscore                    0\n",
      "Item_Outlet_Sales_zscore           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Data:\",testing_data_processed.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6f5d757-cd20-4c75-8e34-ab65c9dd5190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model  Training R²  Testing R²\n",
      "0             Linear Regression     0.773093    0.772199\n",
      "1                 Random Forest     0.985479    0.851509\n",
      "2     Support Vector Regression     0.061300    0.046764\n",
      "3                KNN Regression     0.772143    0.671690\n",
      "4            XGBoost Regression     0.984548    0.870394\n",
      "5              Lasso Regression     0.772640    0.773555\n",
      "6              Ridge Regression     0.773065    0.772340\n",
      "7           AdaBoost Regression     0.837890    0.759973\n",
      "8  Gradient Boosting Regression     0.907815    0.866517\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Separating features and target variable\n",
    "X_train = training_data_processed.drop('Item_Outlet_Sales', axis=1)\n",
    "y_train = training_data_processed['Item_Outlet_Sales']\n",
    "\n",
    "X_test = testing_data_processed.drop('Item_Outlet_Sales', axis=1)\n",
    "y_test = testing_data_processed['Item_Outlet_Sales']\n",
    "\n",
    "# Initializing models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Support Vector Regression': SVR(),\n",
    "    'KNN Regression': KNeighborsRegressor(),\n",
    "    'XGBoost Regression': XGBRegressor(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'AdaBoost Regression': AdaBoostRegressor(),\n",
    "    'Gradient Boosting Regression': GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "# Dictionary to store R² scores\n",
    "r2_scores = {'Model': [], 'Training R²': [], 'Testing R²': []}\n",
    "\n",
    "# Training the models and calculating R² scores\n",
    "for model_name, model in models.items():\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting on training and testing data\n",
    "    train_preds = model.predict(X_train)\n",
    "    test_preds = model.predict(X_test)\n",
    "\n",
    "    # Calculating R² scores\n",
    "    train_r2 = r2_score(y_train, train_preds)\n",
    "    test_r2 = r2_score(y_test, test_preds)\n",
    "\n",
    "    # Storing results\n",
    "    r2_scores['Model'].append(model_name)\n",
    "    r2_scores['Training R²'].append(train_r2)\n",
    "    r2_scores['Testing R²'].append(test_r2)\n",
    "\n",
    "# Converting results to a DataFrame \n",
    "r2_scores_df = pd.DataFrame(r2_scores)\n",
    "\n",
    "print(r2_scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5aa1e0ad-0e2b-4e2c-91d2-0fcfc507be13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best Parameters for Random Forest: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None, 'max_depth': 10}\n",
      "R² on Training Data (Random Forest): 0.9454\n",
      "R² on Testing Data (Random Forest): 0.8549\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------------------\n",
    "# Random Forest Regressor\n",
    "# ----------------------------------\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define parameter grid for Random Forest\n",
    "param_dist_rf = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None]  # Valid options for max_features\n",
    "}\n",
    "\n",
    "# Initialize Random Forest model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Perform RandomizedSearchCV for Random Forest\n",
    "random_search_rf = RandomizedSearchCV(rf, param_distributions=param_dist_rf, n_iter=10, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "random_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Best Random Forest model\n",
    "best_rf = random_search_rf.best_estimator_\n",
    "\n",
    "# Predictions for Random Forest\n",
    "y_train_pred_rf = best_rf.predict(X_train)\n",
    "y_test_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "# Calculate R² scores for Random Forest\n",
    "train_r2_rf = r2_score(y_train, y_train_pred_rf)\n",
    "test_r2_rf = r2_score(y_test, y_test_pred_rf)\n",
    "\n",
    "# Print Random Forest results\n",
    "print(\"Best Parameters for Random Forest:\", random_search_rf.best_params_)\n",
    "print(f\"R² on Training Data (Random Forest): {train_r2_rf:.4f}\")\n",
    "print(f\"R² on Testing Data (Random Forest): {test_r2_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b169fce9-6bac-482f-9cb6-a01c24675fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best Parameters for XGBoost: {'subsample': 0.9, 'n_estimators': 50, 'max_depth': 7, 'learning_rate': 0.1, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
      "R² on Training Data (XGBoost): 0.9431\n",
      "R² on Testing Data (XGBoost): 0.8941\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid for XGBoost\n",
    "param_dist_xgb = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Initialize XGBoost model\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "# Perform RandomizedSearchCV for XGBoost\n",
    "random_search_xgb = RandomizedSearchCV(xgb, param_distributions=param_dist_xgb, n_iter=10, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "random_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Best XGBoost model\n",
    "best_xgb = random_search_xgb.best_estimator_\n",
    "\n",
    "# Predictions for XGBoost\n",
    "y_train_pred_xgb = best_xgb.predict(X_train)\n",
    "y_test_pred_xgb = best_xgb.predict(X_test)\n",
    "\n",
    "# Calculate R² scores for XGBoost\n",
    "train_r2_xgb = r2_score(y_train, y_train_pred_xgb)\n",
    "test_r2_xgb = r2_score(y_test, y_test_pred_xgb)\n",
    "\n",
    "# Print XGBoost results\n",
    "print(\"Best Parameters for XGBoost:\", random_search_xgb.best_params_)\n",
    "print(f\"R² on Training Data (XGBoost): {train_r2_xgb:.4f}\")\n",
    "print(f\"R² on Testing Data (XGBoost): {test_r2_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb8e444a-c21f-40ed-aa26-3aaa6497c5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best Parameters for Gradient Boosting: {'subsample': 1.0, 'n_estimators': 50, 'max_depth': 7, 'learning_rate': 0.1}\n",
      "R² on Training Data (Gradient Boosting): 0.9497\n",
      "R² on Testing Data (Gradient Boosting): 0.8516\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid for Gradient Boosting\n",
    "param_dist_gb = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize Gradient Boosting model\n",
    "gb = GradientBoostingRegressor()\n",
    "\n",
    "# Perform RandomizedSearchCV for Gradient Boosting\n",
    "random_search_gb = RandomizedSearchCV(gb, param_distributions=param_dist_gb, n_iter=10, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "random_search_gb.fit(X_train, y_train)\n",
    "\n",
    "# Best Gradient Boosting model\n",
    "best_gb = random_search_gb.best_estimator_\n",
    "\n",
    "# Predictions for Gradient Boosting\n",
    "y_train_pred_gb = best_gb.predict(X_train)\n",
    "y_test_pred_gb = best_gb.predict(X_test)\n",
    "\n",
    "# Calculate R² scores for Gradient Boosting\n",
    "train_r2_gb = r2_score(y_train, y_train_pred_gb)\n",
    "test_r2_gb = r2_score(y_test, y_test_pred_gb)\n",
    "\n",
    "# Print Gradient Boosting results\n",
    "print(\"Best Parameters for Gradient Boosting:\", random_search_gb.best_params_)\n",
    "print(f\"R² on Training Data (Gradient Boosting): {train_r2_gb:.4f}\")\n",
    "print(f\"R² on Testing Data (Gradient Boosting): {test_r2_gb:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
